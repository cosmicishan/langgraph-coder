{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fb5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758191245.016696    9930 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from Prompts import planner_prompt\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f030523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Graphs import graph_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3187c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = graph_builder()\n",
    "\n",
    "response = agent.invoke({\"user_prompt\": \"Develop me a nice To-Do Application in Html and CSS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e88ecbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"To-Do App\",\"description\":\"A simple web-based To-Do application for managing tasks.\",\"techstack\":\"HTML, CSS, JavaScript\",\"features\":[\"Display a list of To-Do items\",\"Add new To-Do items\",\"Mark To-Do items as complete\",\"Delete To-Do items\",\"User-friendly interface\"],\"files\":[{\"path\":\"index.html\",\"purpose\":\"Main HTML structure of the To-Do application.\"},{\"path\":\"style.css\",\"purpose\":\"Styles for the To-Do application\\'s layout and appearance.\"},{\"path\":\"script.js\",\"purpose\":\"JavaScript logic for adding, deleting, and marking To-Do items as complete.\"}]}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['plan'].model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5535253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd() / \"generated_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7fe3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/ishan/9c63e104-0a83-464e-8d4f-7e0675ab17ef/Projects/Langgraph Coder')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e15d2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.849999999999994"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_T(GAA, F, OP, Qz1, Qz2):\n",
    "    part1 = 0.1 * GAA\n",
    "    part2 = 0.4 * F\n",
    "    part3 = 0.2 * OP\n",
    "    \n",
    "    # First option inside max\n",
    "    option1 = 0.2 * max(Qz1, Qz2)\n",
    "    \n",
    "    # Second option inside max\n",
    "    option2 = 0.15 * Qz1 + 0.15 * Qz2\n",
    "    \n",
    "    # Take max of the two options\n",
    "    part4 = max(option1, option2)\n",
    "    \n",
    "    # Final T\n",
    "    T = part1 + part2 + part3 + part4\n",
    "    return T\n",
    "\n",
    "Qz1 = 17\n",
    "Qz2 = 30\n",
    "OP = 0\n",
    "GAA = 48\n",
    "F = 70\n",
    "\n",
    "compute_T(GAA, F, OP, Qz1, Qz2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c1294ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('END', {'END': 'Hello', 'coder': 'coder'})\n"
     ]
    }
   ],
   "source": [
    "s = {\"status\": \"DONE\"}\n",
    "choice = (lambda s: \"END\" if s.get(\"status\") == \"DONE\" else \"coder\")(s), {\"END\": \"Hello\", \"coder\": \"coder\"}\n",
    "print(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daae0f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'groq:openai/gpt-oss-120b'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.getenv(\"LLM_MODEL\", \"value does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "942eff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(os.getenv(\"LLM_MODEL\"), temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7489c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"Hello\". We need to respond appropriately. It\\'s a simple greeting. We can respond politely.'}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 72, 'total_tokens': 113, 'completion_time': 0.081653618, 'prompt_time': 0.003759891, 'queue_time': 0.048439989, 'total_time': 0.085413509}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_3a688838c3', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--cd858e6d-137b-49e8-87d5-d90a3d9e7a6f-0', usage_metadata={'input_tokens': 72, 'output_tokens': 41, 'total_tokens': 113})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.with_structured_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
